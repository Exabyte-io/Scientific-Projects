{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Multi-Bin Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import collections\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "import xgboost\n",
    "import imblearn.over_sampling\n",
    "import imblearn.pipeline\n",
    "\n",
    "import sklearn.model_selection\n",
    "import sklearn.multiclass\n",
    "import dscribe.descriptors\n",
    "import tqdm\n",
    "import sklearn.pipeline\n",
    "\n",
    "import functools\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn.impute\n",
    "import seaborn as sns\n",
    "\n",
    "sys.path.append(\"../../../../\")\n",
    "import DigitalEcosystem.utils.figures\n",
    "\n",
    "tqdm.tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Random seeds for reproducibility\n",
    "RANDOM_SEED = 1234\n",
    "import random\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Read in the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load up the data\n",
    "data_path = \"../../httpot/full_featurized_data.pkl\"\n",
    "data = pd.read_pickle(data_path)\n",
    "\n",
    "cols_to_drop = ['formula',\n",
    "                'discovery_process (unitless)',\n",
    "                'potcars (unitless)',\n",
    "                'is_hubbard (unitless)',\n",
    "                'energy_per_atom (eV)',\n",
    "                'exfoliation_energy_per_atom (eV/atom)',\n",
    "                'is_bandgap_direct (unitless)',\n",
    "                'is_metal (unitless)',\n",
    "                'energy_vdw_per_atom (eV/atom)',\n",
    "                'total_magnetization (Bohr Magneton)']\n",
    "target_column = ['bandgap (eV)']\n",
    "matpedia_id = ['2dm_id (unitless)']\n",
    "atoms_col = ['atoms_object (unitless)']\n",
    "\n",
    "xenonpy_descriptors = [col for col in data.columns if \":\" in col]\n",
    "matminer_descriptors = [\n",
    "    'bond_length_average',\n",
    "    'bond_angle_average',\n",
    "    'average_cn',\n",
    "    'global_instability',\n",
    "    'perimeter_area_ratio',\n",
    "    'ewald_energy_per_atom',\n",
    "    'structural complexity per atom',\n",
    "    'structural complexity per cell',\n",
    "    'n_symmetry_ops'\n",
    "\n",
    "]\n",
    "xenonpy_matminer_descriptors = xenonpy_descriptors + matminer_descriptors#%%\n",
    "target = ['bandgap (eV)']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Featurization\n",
    "\n",
    "Here, we use the Sine Matrix eigenspectrum (DScribe Documentation here: [Link](https://singroup.github.io/dscribe/0.3.x/tutorials/sine_matrix.html)) as our input feature to determine metallicity. We'd also tried the Ewald Summation Matrix eigenspectrum (DScribe Documentation here: [Link](https://singroup.github.io/dscribe/latest/tutorials/descriptors/ewald_sum_matrix.html)), but found that the Sine Matrix led to better performnance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6351/6351 [00:10<00:00, 632.07it/s]\n"
     ]
    }
   ],
   "source": [
    "# Generate the Sine Matrix Fingerprint\n",
    "max_atoms = max(data['atoms_object (unitless)'].apply(len))\n",
    "sine_eigenspectrum = dscribe.descriptors.SineMatrix(n_atoms_max=max_atoms,\n",
    "                                                         permutation='eigenspectrum',\n",
    "                                                         sparse=False)\n",
    "data['sine_matrix'] = data['atoms_object (unitless)'].progress_apply(lambda atoms: np.real(sine_eigenspectrum.create(atoms))).fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "Next, we'll label our data. We'll say that it's a metal if its DFT bandgap is less than 0.1 eV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Discretize the different parts of the bandgap\n",
    "cutoffs = {\n",
    "    \"metals\": (0, 0, 0.2),\n",
    "    \"semiconductors\": (1, 0.2, 1.14), # Si is 1.14 at 302K\n",
    "    \"wide_bandgap\": (2, 1.14, 3.4),\n",
    "    \"ultrawide_bandgap\": (3, 3.4, 15)\n",
    "}\n",
    "\n",
    "def assign_bandgap_category(bandgap):\n",
    "    for category, (label, low, high) in cutoffs.items():\n",
    "        if low <= bandgap < high:\n",
    "            return label\n",
    "    else:\n",
    "        raise ValueError\n",
    "        \n",
    "data['bandgap_category'] = data['bandgap (eV)'].apply(assign_bandgap_category)\n",
    "    \n",
    "train, test = sklearn.model_selection.train_test_split(data, test_size=0.1, stratify=data['bandgap_category'], random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Train/Test Split\n",
    "Then, we'll split up our data into a training and testing set. We'll stratify our dataset to ensure the same proportion of metals are found in both the training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Pull out the X and Y values\n",
    "def get_x_y(df):\n",
    "    x = np.nan_to_num(np.hstack([np.vstack(df['sine_matrix']), df[xenonpy_matminer_descriptors].to_numpy()]))\n",
    "    y = df['bandgap_category'].to_numpy()\n",
    "    return x,y\n",
    "train_x, train_y = get_x_y(train)\n",
    "test_x, test_y = get_x_y(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# SMOTE\n",
    "\n",
    "To avoid contaminating our test set with information about the training set, we perform K-means SMOTE *after* the train/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({3: 490, 0: 2832, 2: 1488, 1: 905})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections.Counter(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({3: 2832, 0: 2832, 2: 2832, 1: 2832})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upsample the training set with SMOTE\n",
    "smoter = imblearn.over_sampling.SMOTE(\n",
    "    sampling_strategy='all',\n",
    "    random_state=RANDOM_SEED\n",
    ")\n",
    "res_x, res_y = smoter.fit_resample(train_x, train_y)\n",
    "collections.Counter(res_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Hyperparameter Optimization\n",
    "\n",
    "For this work, we'll use an XGBoost classifier. Several of its most important hyperparameters are tuned via Optuna, a Bayesian optimization framework implented in Python.\n",
    "\n",
    "In addition to optimizing the hyperparameters, we'll also investigate the use of a scaler. Optuna can choose from the following options:\n",
    "1. No scaler being applied\n",
    "2. A Min/Max scaler\n",
    "3. A StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "current_pipeline = None\n",
    "best_pipeline = None\n",
    "\n",
    "def keep_best_bandgap_model(study, trial):\n",
    "    \"\"\"\n",
    "    Records the best bandgap model found so far\n",
    "    \"\"\"\n",
    "    global best_pipeline\n",
    "    try:\n",
    "        if study.best_trial == trial:\n",
    "            best_pipeline = current_pipeline\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "def objective(trial: optuna.Trial):\n",
    "    global current_pipeline\n",
    "\n",
    "    tr_x, val_x, tr_y, val_y = sklearn.model_selection.train_test_split(res_x, res_y, test_size=0.2, random_state=RANDOM_SEED)\n",
    "\n",
    "    current_pipeline = sklearn.pipeline.Pipeline([\n",
    "        (\"MinMaxScaler\", sklearn.preprocessing.MinMaxScaler()),\n",
    "        (\"XGB_Classifier\", xgboost.sklearn.XGBClassifier(\n",
    "                                               learning_rate=trial.suggest_float('learning_rate', 0, 1),\n",
    "                                               min_split_loss=trial.suggest_float('min_split_loss', 0, 1),\n",
    "                                               max_depth=trial.suggest_int('max_depth', 1, 100),\n",
    "                                               min_child_weight=trial.suggest_float('min_child_weight', 0, 10),\n",
    "                                               reg_lambda=trial.suggest_float('reg_lambda', 0, 2),\n",
    "                                               reg_alpha=trial.suggest_float('reg_alpha', 0, 2),\n",
    "                                               n_estimators=100,\n",
    "                                               n_jobs=-1,\n",
    "                                               objective='multi:softprob',\n",
    "                                               use_label_encoder=False,\n",
    "                                               random_state=RANDOM_SEED),)\n",
    "    ])\n",
    "\n",
    "    pruning_callback = optuna.integration.XGBoostPruningCallback(trial, 'validation_0-mlogloss')\n",
    "\n",
    "    current_pipeline.fit(X=tr_x, y=tr_y,\n",
    "                         **{\n",
    "                            'XGB_Classifier__eval_set': [[val_x, val_y]],\n",
    "                            'XGB_Classifier__eval_metric': 'mlogloss',\n",
    "                            'XGB_Classifier__early_stopping_rounds': 5,\n",
    "                            'XGB_Classifier__callbacks': [pruning_callback],\n",
    "                            'XGB_Classifier__verbose': False,\n",
    "                         })\n",
    "\n",
    "    preds = current_pipeline.predict(val_x)\n",
    "    pred_labels = np.rint(preds)\n",
    "    f1 = sklearn.metrics.f1_score(val_y, pred_labels, average='macro')\n",
    "\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "We'll run Optuna using its TPE Sampler (the default; documentation here: [Link](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.samplers.TPESampler.html)) with a random seed supplied. Additionally, we'll use the HyperBand pruner to prune trials that are not promising (Documentation link here: [Link](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.pruners.HyperbandPruner.html)).\n",
    "\n",
    "We choose the HyperBand pruner because it's demonstrated accelerate convergence faster than many of the other pruning techniques available in Optuna: [Blogpost Link](https://tech.preferred.jp/en/blog/how-we-implement-hyperband-in-optuna/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-20 10:39:14,179]\u001b[0m A new study created in memory with name: no-name-4c187dac-1870-40f5-a0f1-6921870c2105\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(\n",
    "    sampler = optuna.samplers.TPESampler(\n",
    "        seed=RANDOM_SEED,\n",
    "        warn_independent_sampling=True,\n",
    "        consider_endpoints=True,\n",
    "    ),\n",
    "    pruner = optuna.pruners.HyperbandPruner(\n",
    "        min_resource=1,\n",
    "        max_resource=100),\n",
    "    direction='maximize',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-20 10:39:17,524]\u001b[0m Trial 0 finished with value: 0.7324398755098475 and parameters: {'learning_rate': 0.1915194503788923, 'min_split_loss': 0.6221087710398319, 'max_depth': 44, 'min_child_weight': 7.853585837137692, 'reg_lambda': 1.559951616237607, 'reg_alpha': 0.5451852105652832}. Best is trial 0 with value: 0.7324398755098475.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:39:20,599]\u001b[0m Trial 1 finished with value: 0.7300266379471264 and parameters: {'learning_rate': 0.2764642551430967, 'min_split_loss': 0.8018721775350193, 'max_depth': 96, 'min_child_weight': 8.759326347420947, 'reg_lambda': 0.7156345399157333, 'reg_alpha': 1.0019902510469174}. Best is trial 0 with value: 0.7324398755098475.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:39:24,145]\u001b[0m Trial 2 finished with value: 0.7573652869566175 and parameters: {'learning_rate': 0.6834629351721363, 'min_split_loss': 0.7127020269829002, 'max_depth': 38, 'min_child_weight': 5.611961860656249, 'reg_lambda': 1.0061663306156194, 'reg_alpha': 0.027536899181364483}. Best is trial 2 with value: 0.7573652869566175.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:39:27,387]\u001b[0m Trial 3 finished with value: 0.7480808529461316 and parameters: {'learning_rate': 0.772826621612374, 'min_split_loss': 0.8826411906361166, 'max_depth': 37, 'min_child_weight': 6.153961784334937, 'reg_lambda': 0.1507624832859531, 'reg_alpha': 0.737648012003949}. Best is trial 2 with value: 0.7573652869566175.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:39:30,259]\u001b[0m Trial 4 finished with value: 0.7301753123506594 and parameters: {'learning_rate': 0.9331401019825216, 'min_split_loss': 0.6513781432265774, 'max_depth': 40, 'min_child_weight': 7.887301429407455, 'reg_lambda': 0.6336722443377425, 'reg_alpha': 1.1361973052521384}. Best is trial 2 with value: 0.7573652869566175.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:39:31,870]\u001b[0m Trial 5 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:39:33,083]\u001b[0m Trial 6 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:39:36,923]\u001b[0m Trial 7 finished with value: 0.7474417193392829 and parameters: {'learning_rate': 0.04735527880151513, 'min_split_loss': 0.6748809435823302, 'max_depth': 60, 'min_child_weight': 5.333101629987506, 'reg_lambda': 0.08664812538960698, 'reg_alpha': 1.1228661601267957}. Best is trial 2 with value: 0.7573652869566175.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:39:40,715]\u001b[0m Trial 8 finished with value: 0.770665132236273 and parameters: {'learning_rate': 0.329668445620915, 'min_split_loss': 0.5029668331126184, 'max_depth': 12, 'min_child_weight': 6.071937062184846, 'reg_lambda': 1.1318892861010628, 'reg_alpha': 0.01352812398000558}. Best is trial 8 with value: 0.770665132236273.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:39:44,102]\u001b[0m Trial 9 finished with value: 0.7338976920455833 and parameters: {'learning_rate': 0.617441708804297, 'min_split_loss': 0.9121228864331543, 'max_depth': 80, 'min_child_weight': 9.920814661883615, 'reg_lambda': 1.917603524305733, 'reg_alpha': 1.5839282705832796}. Best is trial 8 with value: 0.770665132236273.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:39:46,026]\u001b[0m Trial 10 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:39:49,746]\u001b[0m Trial 11 finished with value: 0.7549237429158713 and parameters: {'learning_rate': 0.45164840826085906, 'min_split_loss': 0.9820047415219545, 'max_depth': 13, 'min_child_weight': 1.193808979262484, 'reg_lambda': 1.4770461122866936, 'reg_alpha': 1.1746072669279692}. Best is trial 8 with value: 0.770665132236273.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:39:51,510]\u001b[0m Trial 12 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:39:54,359]\u001b[0m Trial 13 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:39:55,631]\u001b[0m Trial 14 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:39:56,934]\u001b[0m Trial 15 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:39:59,142]\u001b[0m Trial 16 finished with value: 0.6839958413016423 and parameters: {'learning_rate': 0.5368781929244097, 'min_split_loss': 0.8192020670641583, 'max_depth': 6, 'min_child_weight': 6.694217430745488, 'reg_lambda': 1.534233256758945, 'reg_alpha': 1.4162307239552077}. Best is trial 8 with value: 0.770665132236273.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:39:59,449]\u001b[0m Trial 17 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:40:02,648]\u001b[0m Trial 18 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:40:06,390]\u001b[0m Trial 19 finished with value: 0.7487417546240356 and parameters: {'learning_rate': 0.7690206579203309, 'min_split_loss': 0.8005320027404571, 'max_depth': 27, 'min_child_weight': 5.640357598743432, 'reg_lambda': 0.35942674557142573, 'reg_alpha': 0.5176260567725972}. Best is trial 8 with value: 0.770665132236273.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:40:11,441]\u001b[0m Trial 20 finished with value: 0.8014663216635425 and parameters: {'learning_rate': 0.7968671837251966, 'min_split_loss': 0.5577608284274495, 'max_depth': 97, 'min_child_weight': 1.4715689989299718, 'reg_lambda': 0.05929400107083116, 'reg_alpha': 1.1877869852495435}. Best is trial 20 with value: 0.8014663216635425.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:40:11,832]\u001b[0m Trial 21 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:40:14,461]\u001b[0m Trial 22 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:40:18,103]\u001b[0m Trial 23 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:40:20,018]\u001b[0m Trial 24 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:40:25,977]\u001b[0m Trial 25 finished with value: 0.7604801722644898 and parameters: {'learning_rate': 0.8790691615146757, 'min_split_loss': 0.2526157550465302, 'max_depth': 35, 'min_child_weight': 1.8258873158030875, 'reg_lambda': 1.8035921027419841, 'reg_alpha': 1.413056326343595}. Best is trial 20 with value: 0.8014663216635425.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:40:29,701]\u001b[0m Trial 26 finished with value: 0.7489832159850796 and parameters: {'learning_rate': 0.7266584615621408, 'min_split_loss': 0.9000878368097077, 'max_depth': 78, 'min_child_weight': 5.991547806042924, 'reg_lambda': 0.5822504897957497, 'reg_alpha': 0.30279052881486423}. Best is trial 20 with value: 0.8014663216635425.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:40:31,380]\u001b[0m Trial 27 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:40:35,656]\u001b[0m Trial 28 finished with value: 0.7654915365030298 and parameters: {'learning_rate': 0.8538985671256417, 'min_split_loss': 0.287062425000009, 'max_depth': 18, 'min_child_weight': 1.3402120599884282, 'reg_lambda': 1.989307657288589, 'reg_alpha': 0.35899573893878367}. Best is trial 20 with value: 0.8014663216635425.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:40:37,625]\u001b[0m Trial 29 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:40:38,116]\u001b[0m Trial 30 finished with value: 0.5235503701058044 and parameters: {'learning_rate': 0.31754682302719583, 'min_split_loss': 0.5682914046591072, 'max_depth': 1, 'min_child_weight': 9.00648621155092, 'reg_lambda': 1.9544828618451742, 'reg_alpha': 1.1137893582736698}. Best is trial 20 with value: 0.8014663216635425.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:40:39,127]\u001b[0m Trial 31 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:40:40,436]\u001b[0m Trial 32 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:40:46,665]\u001b[0m Trial 33 finished with value: 0.7693239223681101 and parameters: {'learning_rate': 0.08477384339419014, 'min_split_loss': 0.3330024657291001, 'max_depth': 73, 'min_child_weight': 1.4243537334181722, 'reg_lambda': 1.104937878995091, 'reg_alpha': 0.5460865193673712}. Best is trial 20 with value: 0.8014663216635425.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:40:48,121]\u001b[0m Trial 34 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:40:52,593]\u001b[0m Trial 35 finished with value: 0.7619752268316078 and parameters: {'learning_rate': 0.9744951380872597, 'min_split_loss': 0.6677869061450377, 'max_depth': 26, 'min_child_weight': 1.0831149418272878, 'reg_lambda': 1.5523614463477644, 'reg_alpha': 1.564955985200404}. Best is trial 20 with value: 0.8014663216635425.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:40:57,127]\u001b[0m Trial 36 finished with value: 0.7404816185266676 and parameters: {'learning_rate': 0.7616039143074941, 'min_split_loss': 0.9144031132693238, 'max_depth': 66, 'min_child_weight': 5.683675815729324, 'reg_lambda': 0.4035113849059566, 'reg_alpha': 1.3965927511035223}. Best is trial 20 with value: 0.8014663216635425.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:40:58,474]\u001b[0m Trial 37 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:41:03,386]\u001b[0m Trial 38 finished with value: 0.7533899920153528 and parameters: {'learning_rate': 0.791879098366757, 'min_split_loss': 0.8694510732552394, 'max_depth': 36, 'min_child_weight': 6.031768122170613, 'reg_lambda': 0.18693697414222765, 'reg_alpha': 0.7570544679709414}. Best is trial 20 with value: 0.8014663216635425.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:41:06,537]\u001b[0m Trial 39 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:41:07,834]\u001b[0m Trial 40 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:41:10,314]\u001b[0m Trial 41 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:41:11,930]\u001b[0m Trial 42 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:41:15,397]\u001b[0m Trial 43 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:41:18,440]\u001b[0m Trial 44 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:41:19,836]\u001b[0m Trial 45 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:41:21,118]\u001b[0m Trial 46 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:41:23,988]\u001b[0m Trial 47 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:41:28,194]\u001b[0m Trial 48 finished with value: 0.7489143716504849 and parameters: {'learning_rate': 0.21563406298839582, 'min_split_loss': 0.7349451885621964, 'max_depth': 37, 'min_child_weight': 8.016025985027602, 'reg_lambda': 1.5654711839507525, 'reg_alpha': 1.402710758473386}. Best is trial 20 with value: 0.8014663216635425.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:41:32,032]\u001b[0m Trial 49 finished with value: 0.7434119922155218 and parameters: {'learning_rate': 0.6227765866031991, 'min_split_loss': 0.49368264574711207, 'max_depth': 85, 'min_child_weight': 7.120969869436474, 'reg_lambda': 0.8878179628317049, 'reg_alpha': 0.062069722266665295}. Best is trial 20 with value: 0.8014663216635425.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:41:33,773]\u001b[0m Trial 50 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:41:35,536]\u001b[0m Trial 51 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:41:39,316]\u001b[0m Trial 52 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:41:43,300]\u001b[0m Trial 53 finished with value: 0.7509994035090344 and parameters: {'learning_rate': 0.7115249802509586, 'min_split_loss': 0.983851712013202, 'max_depth': 38, 'min_child_weight': 6.001616184342132, 'reg_lambda': 0.3698326882442228, 'reg_alpha': 0.6521817195816844}. Best is trial 20 with value: 0.8014663216635425.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:41:44,524]\u001b[0m Trial 54 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:41:47,444]\u001b[0m Trial 55 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:41:50,952]\u001b[0m Trial 56 finished with value: 0.7529425255596525 and parameters: {'learning_rate': 0.17146526096424974, 'min_split_loss': 0.7370864936885216, 'max_depth': 13, 'min_child_weight': 3.696498749466268, 'reg_lambda': 1.2086680096720528, 'reg_alpha': 0.20620887771129448}. Best is trial 20 with value: 0.8014663216635425.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:41:56,183]\u001b[0m Trial 57 finished with value: 0.8170355401948264 and parameters: {'learning_rate': 0.8023741823372101, 'min_split_loss': 0.9455532358421244, 'max_depth': 98, 'min_child_weight': 8.81232246338927, 'reg_lambda': 1.2553638429279503, 'reg_alpha': 1.8609730668053313}. Best is trial 57 with value: 0.8170355401948264.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:41:57,689]\u001b[0m Trial 58 finished with value: 0.660521652543186 and parameters: {'learning_rate': 0.7247899531024389, 'min_split_loss': 0.7166778860553562, 'max_depth': 5, 'min_child_weight': 4.394817751674749, 'reg_lambda': 0.5641395662321755, 'reg_alpha': 0.6699919377838546}. Best is trial 57 with value: 0.8170355401948264.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:42:01,202]\u001b[0m Trial 59 finished with value: 0.7520651643759695 and parameters: {'learning_rate': 0.6901501275825123, 'min_split_loss': 0.9383468950357314, 'max_depth': 68, 'min_child_weight': 5.969108327633417, 'reg_lambda': 0.6673386851266077, 'reg_alpha': 0.6427622656450298}. Best is trial 57 with value: 0.8170355401948264.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:42:05,892]\u001b[0m Trial 60 finished with value: 0.7676362300153381 and parameters: {'learning_rate': 0.0835270070444003, 'min_split_loss': 0.760849147057386, 'max_depth': 51, 'min_child_weight': 6.610474176084522, 'reg_lambda': 1.260628884968563, 'reg_alpha': 0.741853654915055}. Best is trial 57 with value: 0.8170355401948264.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:42:09,127]\u001b[0m Trial 61 finished with value: 0.7301089522271306 and parameters: {'learning_rate': 0.4467401517308447, 'min_split_loss': 0.4151082201975932, 'max_depth': 49, 'min_child_weight': 9.833235733884662, 'reg_lambda': 0.7468474147070747, 'reg_alpha': 0.02481396345542719}. Best is trial 57 with value: 0.8170355401948264.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:42:11,600]\u001b[0m Trial 62 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:42:15,097]\u001b[0m Trial 63 finished with value: 0.7490358279320263 and parameters: {'learning_rate': 0.7800469775705543, 'min_split_loss': 0.49087526056272135, 'max_depth': 74, 'min_child_weight': 5.723652311099249, 'reg_lambda': 0.015955004941296425, 'reg_alpha': 0.5555967922871367}. Best is trial 57 with value: 0.8170355401948264.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:42:18,398]\u001b[0m Trial 64 finished with value: 0.7420471576829284 and parameters: {'learning_rate': 0.8304527987088497, 'min_split_loss': 0.028527587815146138, 'max_depth': 83, 'min_child_weight': 7.50084214382755, 'reg_lambda': 0.0006290967324200647, 'reg_alpha': 0.4410319074100444}. Best is trial 57 with value: 0.8170355401948264.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:42:22,033]\u001b[0m Trial 65 finished with value: 0.7274117174613333 and parameters: {'learning_rate': 0.9904084283970859, 'min_split_loss': 0.46545823229860017, 'max_depth': 74, 'min_child_weight': 9.548215852831717, 'reg_lambda': 0.22448628329307949, 'reg_alpha': 0.5410535831109723}. Best is trial 57 with value: 0.8170355401948264.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:42:26,167]\u001b[0m Trial 66 finished with value: 0.7420812346541497 and parameters: {'learning_rate': 0.6634854867933933, 'min_split_loss': 0.04249707917463269, 'max_depth': 89, 'min_child_weight': 6.448907781245075, 'reg_lambda': 1.4656492595514174, 'reg_alpha': 0.004644240074552941}. Best is trial 57 with value: 0.8170355401948264.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:42:27,548]\u001b[0m Trial 67 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:42:28,991]\u001b[0m Trial 68 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:42:32,432]\u001b[0m Trial 69 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:42:36,012]\u001b[0m Trial 70 finished with value: 0.7486462959441993 and parameters: {'learning_rate': 0.9219033377990289, 'min_split_loss': 0.873276070344208, 'max_depth': 36, 'min_child_weight': 6.301331125022921, 'reg_lambda': 0.7156539186833821, 'reg_alpha': 0.4256398752969299}. Best is trial 57 with value: 0.8170355401948264.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:42:38,692]\u001b[0m Trial 71 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:42:41,383]\u001b[0m Trial 72 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:42:43,824]\u001b[0m Trial 73 finished with value: 0.707246645913086 and parameters: {'learning_rate': 0.22331922312265218, 'min_split_loss': 0.4195637917308277, 'max_depth': 8, 'min_child_weight': 6.508390701366923, 'reg_lambda': 1.5113722979018749, 'reg_alpha': 1.8642024526236245}. Best is trial 57 with value: 0.8170355401948264.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:42:45,345]\u001b[0m Trial 74 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:42:48,918]\u001b[0m Trial 75 finished with value: 0.7369605594919357 and parameters: {'learning_rate': 0.3764041595819979, 'min_split_loss': 0.29692728344953345, 'max_depth': 38, 'min_child_weight': 8.276993588036342, 'reg_lambda': 1.8022790705005896, 'reg_alpha': 0.8546075697149924}. Best is trial 57 with value: 0.8170355401948264.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:42:51,636]\u001b[0m Trial 76 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:42:56,139]\u001b[0m Trial 77 finished with value: 0.7565405877763847 and parameters: {'learning_rate': 0.35101566975307025, 'min_split_loss': 0.992109749967658, 'max_depth': 75, 'min_child_weight': 3.422311342535008, 'reg_lambda': 0.5891201322510426, 'reg_alpha': 0.08341730080048576}. Best is trial 57 with value: 0.8170355401948264.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:42:57,343]\u001b[0m Trial 78 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:42:58,552]\u001b[0m Trial 79 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:43:01,584]\u001b[0m Trial 80 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:43:04,137]\u001b[0m Trial 81 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:43:08,506]\u001b[0m Trial 82 finished with value: 0.7460977977531178 and parameters: {'learning_rate': 0.043676675291595135, 'min_split_loss': 0.3845709030055059, 'max_depth': 57, 'min_child_weight': 4.227982298715095, 'reg_lambda': 1.1373886191055136, 'reg_alpha': 0.5378674053583958}. Best is trial 57 with value: 0.8170355401948264.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:43:09,896]\u001b[0m Trial 83 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:43:13,516]\u001b[0m Trial 84 finished with value: 0.7501655369222514 and parameters: {'learning_rate': 0.0021894308231216186, 'min_split_loss': 0.04196524456467021, 'max_depth': 15, 'min_child_weight': 5.982371851051667, 'reg_lambda': 0.2129210440237217, 'reg_alpha': 0.5943179723486358}. Best is trial 57 with value: 0.8170355401948264.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:43:15,933]\u001b[0m Trial 85 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:43:20,186]\u001b[0m Trial 86 finished with value: 0.7505645969050769 and parameters: {'learning_rate': 0.17972063425693946, 'min_split_loss': 0.05223725532195428, 'max_depth': 100, 'min_child_weight': 5.860016797780176, 'reg_lambda': 1.0589853283905404, 'reg_alpha': 0.6192287927567656}. Best is trial 57 with value: 0.8170355401948264.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:43:23,641]\u001b[0m Trial 87 finished with value: 0.7448140351650212 and parameters: {'learning_rate': 0.6848007165140348, 'min_split_loss': 0.03195025393450744, 'max_depth': 87, 'min_child_weight': 6.689384390648444, 'reg_lambda': 1.3745346221844192, 'reg_alpha': 0.0029427543130933764}. Best is trial 57 with value: 0.8170355401948264.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:43:26,175]\u001b[0m Trial 88 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:43:27,635]\u001b[0m Trial 89 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:43:29,358]\u001b[0m Trial 90 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:43:32,564]\u001b[0m Trial 91 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:43:33,936]\u001b[0m Trial 92 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:43:35,237]\u001b[0m Trial 93 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:43:37,592]\u001b[0m Trial 94 finished with value: 0.6296722125337042 and parameters: {'learning_rate': 0.05839198991213279, 'min_split_loss': 0.6213248602513616, 'max_depth': 3, 'min_child_weight': 8.550546861316567, 'reg_lambda': 0.6126744057325448, 'reg_alpha': 1.5175668895078083}. Best is trial 57 with value: 0.8170355401948264.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:43:41,183]\u001b[0m Trial 95 finished with value: 0.7340255424749361 and parameters: {'learning_rate': 0.3970320491936367, 'min_split_loss': 0.9527077328739835, 'max_depth': 43, 'min_child_weight': 9.378714900678371, 'reg_lambda': 0.7030710233808679, 'reg_alpha': 1.9751438212805867}. Best is trial 57 with value: 0.8170355401948264.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:43:43,966]\u001b[0m Trial 96 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:43:45,779]\u001b[0m Trial 97 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:43:48,553]\u001b[0m Trial 98 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:43:52,008]\u001b[0m Trial 99 finished with value: 0.7508923000026838 and parameters: {'learning_rate': 0.7412191035136287, 'min_split_loss': 0.9504223373061099, 'max_depth': 55, 'min_child_weight': 6.065479877356149, 'reg_lambda': 0.6364125297356418, 'reg_alpha': 0.5072646290747029}. Best is trial 57 with value: 0.8170355401948264.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:43:54,361]\u001b[0m Trial 100 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:43:55,828]\u001b[0m Trial 101 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:44:05,164]\u001b[0m Trial 102 finished with value: 0.7769416312749302 and parameters: {'learning_rate': 0.006725783361153842, 'min_split_loss': 0.8416600180902608, 'max_depth': 16, 'min_child_weight': 3.0699103420759286, 'reg_lambda': 0.3365651790974762, 'reg_alpha': 0.7902708935389742}. Best is trial 57 with value: 0.8170355401948264.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:44:07,506]\u001b[0m Trial 103 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:44:11,132]\u001b[0m Trial 104 finished with value: 0.7370566532206013 and parameters: {'learning_rate': 0.5632751101398661, 'min_split_loss': 0.03816418217864814, 'max_depth': 57, 'min_child_weight': 6.5887348864820865, 'reg_lambda': 0.36653269878535566, 'reg_alpha': 1.5948226161822772}. Best is trial 57 with value: 0.8170355401948264.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:44:13,719]\u001b[0m Trial 105 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:44:15,190]\u001b[0m Trial 106 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:44:17,915]\u001b[0m Trial 107 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:44:21,327]\u001b[0m Trial 108 finished with value: 0.7339873392058774 and parameters: {'learning_rate': 0.6123674294689488, 'min_split_loss': 0.5556533844497369, 'max_depth': 63, 'min_child_weight': 6.86180075331102, 'reg_lambda': 0.4807650750455732, 'reg_alpha': 1.5758555759590793}. Best is trial 57 with value: 0.8170355401948264.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:44:24,808]\u001b[0m Trial 109 finished with value: 0.7524539084368604 and parameters: {'learning_rate': 0.6521692539452859, 'min_split_loss': 0.8855467284128339, 'max_depth': 14, 'min_child_weight': 3.597643408988895, 'reg_lambda': 0.1003370598586602, 'reg_alpha': 0.31022980478427375}. Best is trial 57 with value: 0.8170355401948264.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:44:26,262]\u001b[0m Trial 110 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:44:30,788]\u001b[0m Trial 111 finished with value: 0.8071349349600045 and parameters: {'learning_rate': 0.9654001121239194, 'min_split_loss': 0.9064695061235561, 'max_depth': 48, 'min_child_weight': 5.90864445202656, 'reg_lambda': 0.837990826696125, 'reg_alpha': 0.4846207921039186}. Best is trial 57 with value: 0.8170355401948264.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:44:33,164]\u001b[0m Trial 112 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:44:36,416]\u001b[0m Trial 113 finished with value: 0.7355475398846036 and parameters: {'learning_rate': 0.9562379065023405, 'min_split_loss': 0.9096302350501724, 'max_depth': 56, 'min_child_weight': 6.870585322980054, 'reg_lambda': 0.8400799312530787, 'reg_alpha': 0.8255884857523619}. Best is trial 57 with value: 0.8170355401948264.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:44:37,846]\u001b[0m Trial 114 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:44:40,596]\u001b[0m Trial 115 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:44:42,048]\u001b[0m Trial 116 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:44:45,972]\u001b[0m Trial 117 finished with value: 0.7508153541373649 and parameters: {'learning_rate': 0.8179270081114529, 'min_split_loss': 0.6256448297756986, 'max_depth': 93, 'min_child_weight': 5.134410751061902, 'reg_lambda': 1.3696136833079802, 'reg_alpha': 0.3591478443660929}. Best is trial 57 with value: 0.8170355401948264.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:44:51,574]\u001b[0m Trial 118 finished with value: 0.5014760862926935 and parameters: {'learning_rate': 6.49409054605532e-05, 'min_split_loss': 0.001967594514499682, 'max_depth': 1, 'min_child_weight': 0.031218573343134715, 'reg_lambda': 0.29790939546212947, 'reg_alpha': 0.8721245074876885}. Best is trial 57 with value: 0.8170355401948264.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:44:54,919]\u001b[0m Trial 119 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:45:00,397]\u001b[0m Trial 120 finished with value: 0.7528199792021175 and parameters: {'learning_rate': 0.18497463231229364, 'min_split_loss': 0.507439505670614, 'max_depth': 23, 'min_child_weight': 2.722019580675197, 'reg_lambda': 0.3896908873421844, 'reg_alpha': 1.990819412479797}. Best is trial 57 with value: 0.8170355401948264.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:45:07,017]\u001b[0m Trial 121 finished with value: 0.839675076803229 and parameters: {'learning_rate': 0.46824478980639245, 'min_split_loss': 0.1413212233155759, 'max_depth': 10, 'min_child_weight': 0.30488756153608465, 'reg_lambda': 0.811230740887394, 'reg_alpha': 0.002319147157717083}. Best is trial 121 with value: 0.839675076803229.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:45:09,876]\u001b[0m Trial 122 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:45:12,753]\u001b[0m Trial 123 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:45:16,222]\u001b[0m Trial 124 finished with value: 0.7484445863801629 and parameters: {'learning_rate': 0.7974086361371079, 'min_split_loss': 0.70162102640711, 'max_depth': 38, 'min_child_weight': 5.740374544404726, 'reg_lambda': 0.4602706229686001, 'reg_alpha': 0.5897980284126013}. Best is trial 121 with value: 0.839675076803229.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:45:17,582]\u001b[0m Trial 125 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:45:18,842]\u001b[0m Trial 126 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:45:20,242]\u001b[0m Trial 127 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:45:21,459]\u001b[0m Trial 128 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:45:22,765]\u001b[0m Trial 129 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:45:26,168]\u001b[0m Trial 130 finished with value: 0.75705854770816 and parameters: {'learning_rate': 0.8985125192744974, 'min_split_loss': 0.6777375056301694, 'max_depth': 78, 'min_child_weight': 4.24356088201302, 'reg_lambda': 0.24210826241996156, 'reg_alpha': 1.0257172089027289}. Best is trial 121 with value: 0.839675076803229.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:45:32,335]\u001b[0m Trial 131 finished with value: 0.7735120871910721 and parameters: {'learning_rate': 0.927236502660115, 'min_split_loss': 0.6617402691637303, 'max_depth': 63, 'min_child_weight': 0.02429730623123305, 'reg_lambda': 0.19854027160174947, 'reg_alpha': 1.0050108418993278}. Best is trial 121 with value: 0.839675076803229.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:45:40,275]\u001b[0m Trial 132 finished with value: 0.8282535082462588 and parameters: {'learning_rate': 0.6974968025166376, 'min_split_loss': 0.121241528450026, 'max_depth': 31, 'min_child_weight': 0.20956082878541243, 'reg_lambda': 0.7643575502137064, 'reg_alpha': 0.3049863948113611}. Best is trial 121 with value: 0.839675076803229.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:45:42,364]\u001b[0m Trial 133 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:45:46,397]\u001b[0m Trial 134 finished with value: 0.751905569398584 and parameters: {'learning_rate': 0.651797086775901, 'min_split_loss': 0.677642288394268, 'max_depth': 36, 'min_child_weight': 5.654133215142206, 'reg_lambda': 0.28261194450930005, 'reg_alpha': 0.7162571814248909}. Best is trial 121 with value: 0.839675076803229.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:45:50,773]\u001b[0m Trial 135 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:45:52,246]\u001b[0m Trial 136 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:45:56,144]\u001b[0m Trial 137 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:45:59,125]\u001b[0m Trial 138 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:46:03,225]\u001b[0m Trial 139 finished with value: 0.7526517883413694 and parameters: {'learning_rate': 0.6763891225664459, 'min_split_loss': 0.6832335504252952, 'max_depth': 36, 'min_child_weight': 5.73278972422955, 'reg_lambda': 0.39909602407132033, 'reg_alpha': 0.6909425041462172}. Best is trial 121 with value: 0.839675076803229.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:46:06,007]\u001b[0m Trial 140 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:46:11,740]\u001b[0m Trial 141 finished with value: 0.7736955628107134 and parameters: {'learning_rate': 0.7190309850631176, 'min_split_loss': 0.11917494686972521, 'max_depth': 31, 'min_child_weight': 0.429911402298797, 'reg_lambda': 0.8622648262523874, 'reg_alpha': 0.28498398934927527}. Best is trial 121 with value: 0.839675076803229.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:46:14,642]\u001b[0m Trial 142 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:46:18,023]\u001b[0m Trial 143 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:46:21,698]\u001b[0m Trial 144 finished with value: 0.7445233523100918 and parameters: {'learning_rate': 0.7706565332980945, 'min_split_loss': 0.6065537407560514, 'max_depth': 78, 'min_child_weight': 4.023748477669797, 'reg_lambda': 0.517817110237548, 'reg_alpha': 1.1955017915774726}. Best is trial 121 with value: 0.839675076803229.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:46:24,690]\u001b[0m Trial 145 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:46:27,876]\u001b[0m Trial 146 finished with value: 0.7474922748223122 and parameters: {'learning_rate': 0.48030092667138186, 'min_split_loss': 0.15551091138038248, 'max_depth': 10, 'min_child_weight': 2.1303720186378827, 'reg_lambda': 0.5336608424831187, 'reg_alpha': 0.4716218254826299}. Best is trial 121 with value: 0.839675076803229.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:46:29,479]\u001b[0m Trial 147 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:46:30,813]\u001b[0m Trial 148 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:46:32,179]\u001b[0m Trial 149 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:46:33,580]\u001b[0m Trial 150 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:46:34,849]\u001b[0m Trial 151 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:46:36,007]\u001b[0m Trial 152 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:46:37,607]\u001b[0m Trial 153 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:46:43,076]\u001b[0m Trial 154 finished with value: 0.7437431397942191 and parameters: {'learning_rate': 0.7852470435116213, 'min_split_loss': 0.5415792105930071, 'max_depth': 30, 'min_child_weight': 6.410732362507984, 'reg_lambda': 0.4191203776285605, 'reg_alpha': 0.6053133422395693}. Best is trial 121 with value: 0.839675076803229.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:46:45,836]\u001b[0m Trial 155 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:46:48,526]\u001b[0m Trial 156 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:46:50,963]\u001b[0m Trial 157 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:46:52,265]\u001b[0m Trial 158 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:46:53,687]\u001b[0m Trial 159 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:46:58,392]\u001b[0m Trial 160 finished with value: 0.7653086325339 and parameters: {'learning_rate': 0.7969153752634397, 'min_split_loss': 0.7591757671095146, 'max_depth': 96, 'min_child_weight': 1.187389606610293, 'reg_lambda': 0.7415823000049165, 'reg_alpha': 0.9631045402439739}. Best is trial 121 with value: 0.839675076803229.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:47:01,081]\u001b[0m Trial 161 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:47:09,483]\u001b[0m Trial 162 finished with value: 0.8420744148953054 and parameters: {'learning_rate': 0.8085364626645626, 'min_split_loss': 0.3219167054210489, 'max_depth': 24, 'min_child_weight': 0.005688362868510544, 'reg_lambda': 0.7635746283300472, 'reg_alpha': 0.181728652375804}. Best is trial 162 with value: 0.8420744148953054.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:47:16,982]\u001b[0m Trial 163 finished with value: 0.8415391281372819 and parameters: {'learning_rate': 0.7885276960915188, 'min_split_loss': 0.23328433358734704, 'max_depth': 23, 'min_child_weight': 0.48543058112875, 'reg_lambda': 0.7887065617135401, 'reg_alpha': 0.13599787633747462}. Best is trial 162 with value: 0.8420744148953054.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:47:18,342]\u001b[0m Trial 164 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:47:19,659]\u001b[0m Trial 165 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:47:21,073]\u001b[0m Trial 166 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:47:25,722]\u001b[0m Trial 167 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:47:28,806]\u001b[0m Trial 168 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:47:35,001]\u001b[0m Trial 169 finished with value: 0.7782232616322511 and parameters: {'learning_rate': 0.8320437313444489, 'min_split_loss': 0.2700940641030732, 'max_depth': 43, 'min_child_weight': 0.7200715199806247, 'reg_lambda': 1.3438083833298786, 'reg_alpha': 0.14452736089119103}. Best is trial 162 with value: 0.8420744148953054.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:47:38,406]\u001b[0m Trial 170 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:47:39,603]\u001b[0m Trial 171 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:47:40,911]\u001b[0m Trial 172 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:47:44,403]\u001b[0m Trial 173 finished with value: 0.7484868369155637 and parameters: {'learning_rate': 0.7858328391860463, 'min_split_loss': 0.696211713935619, 'max_depth': 36, 'min_child_weight': 5.846418330315909, 'reg_lambda': 0.46471974331049865, 'reg_alpha': 0.5794041795848366}. Best is trial 162 with value: 0.8420744148953054.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:47:46,978]\u001b[0m Trial 174 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:47:52,731]\u001b[0m Trial 175 finished with value: 0.8327034088216465 and parameters: {'learning_rate': 0.8564774570595708, 'min_split_loss': 0.7277960155986192, 'max_depth': 70, 'min_child_weight': 4.723509390701848, 'reg_lambda': 1.7137458838690016, 'reg_alpha': 1.3294866678086121}. Best is trial 162 with value: 0.8420744148953054.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:47:54,057]\u001b[0m Trial 176 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:47:57,282]\u001b[0m Trial 177 finished with value: 0.7437000867430389 and parameters: {'learning_rate': 0.7680902068667563, 'min_split_loss': 0.6654798152723175, 'max_depth': 50, 'min_child_weight': 6.42488456172396, 'reg_lambda': 0.5985250310520029, 'reg_alpha': 0.5399464389971731}. Best is trial 162 with value: 0.8420744148953054.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:48:02,940]\u001b[0m Trial 178 finished with value: 0.7740549847547172 and parameters: {'learning_rate': 0.7289341686756527, 'min_split_loss': 0.6852152349834778, 'max_depth': 99, 'min_child_weight': 0.3357765530808283, 'reg_lambda': 0.17115681253544837, 'reg_alpha': 1.007949098957536}. Best is trial 162 with value: 0.8420744148953054.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:48:05,310]\u001b[0m Trial 179 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:48:07,690]\u001b[0m Trial 180 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:48:09,548]\u001b[0m Trial 181 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:48:16,520]\u001b[0m Trial 182 finished with value: 0.7688401061446294 and parameters: {'learning_rate': 0.9616666602133173, 'min_split_loss': 0.4015379640460808, 'max_depth': 23, 'min_child_weight': 0.022914464204470353, 'reg_lambda': 0.9500400461288114, 'reg_alpha': 0.20566213913906017}. Best is trial 162 with value: 0.8420744148953054.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:48:20,820]\u001b[0m Trial 183 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:48:22,436]\u001b[0m Trial 184 finished with value: 0.6575844667410979 and parameters: {'learning_rate': 0.7741303835918307, 'min_split_loss': 0.18109030807777116, 'max_depth': 5, 'min_child_weight': 1.9531217569484187, 'reg_lambda': 0.5975783253872554, 'reg_alpha': 0.013436938761364509}. Best is trial 162 with value: 0.8420744148953054.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:48:23,768]\u001b[0m Trial 185 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:48:26,846]\u001b[0m Trial 186 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:48:29,222]\u001b[0m Trial 187 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:48:30,601]\u001b[0m Trial 188 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:48:33,001]\u001b[0m Trial 189 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:48:34,289]\u001b[0m Trial 190 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:48:35,611]\u001b[0m Trial 191 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:48:38,093]\u001b[0m Trial 192 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:48:43,931]\u001b[0m Trial 193 finished with value: 0.7727931290373986 and parameters: {'learning_rate': 0.7168657260767579, 'min_split_loss': 0.6331950422841816, 'max_depth': 100, 'min_child_weight': 0.5443307316814074, 'reg_lambda': 0.5042052495358325, 'reg_alpha': 0.97378813703727}. Best is trial 162 with value: 0.8420744148953054.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:48:45,414]\u001b[0m Trial 194 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:48:50,484]\u001b[0m Trial 195 finished with value: 0.7727739712424637 and parameters: {'learning_rate': 0.5656175481522272, 'min_split_loss': 0.3786464563589511, 'max_depth': 23, 'min_child_weight': 0.9678474706948917, 'reg_lambda': 0.7650439668576662, 'reg_alpha': 0.43153283450354096}. Best is trial 162 with value: 0.8420744148953054.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:48:52,957]\u001b[0m Trial 196 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:48:54,299]\u001b[0m Trial 197 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:48:55,627]\u001b[0m Trial 198 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:48:59,379]\u001b[0m Trial 199 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:49:00,612]\u001b[0m Trial 200 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:49:02,831]\u001b[0m Trial 201 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:49:04,120]\u001b[0m Trial 202 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:49:08,377]\u001b[0m Trial 203 finished with value: 0.772429136324927 and parameters: {'learning_rate': 0.9097778207492697, 'min_split_loss': 0.0034978533067704654, 'max_depth': 42, 'min_child_weight': 1.4565573311290159, 'reg_lambda': 0.4621927354915314, 'reg_alpha': 0.1924883978157898}. Best is trial 162 with value: 0.8420744148953054.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:49:11,509]\u001b[0m Trial 204 finished with value: 0.7319804237997428 and parameters: {'learning_rate': 0.9956585412970645, 'min_split_loss': 0.9779144837036551, 'max_depth': 99, 'min_child_weight': 9.557927430750125, 'reg_lambda': 1.8904283278364158, 'reg_alpha': 1.8508833496178754}. Best is trial 162 with value: 0.8420744148953054.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:49:17,218]\u001b[0m Trial 205 finished with value: 0.8051341722075199 and parameters: {'learning_rate': 0.8067205871539225, 'min_split_loss': 0.8241495908021705, 'max_depth': 100, 'min_child_weight': 1.0781343168561341, 'reg_lambda': 0.009290881896254967, 'reg_alpha': 1.0556844139098267}. Best is trial 162 with value: 0.8420744148953054.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:49:22,720]\u001b[0m Trial 206 finished with value: 0.7752441885416723 and parameters: {'learning_rate': 0.7082729575969539, 'min_split_loss': 0.6874719149594487, 'max_depth': 21, 'min_child_weight': 0.14594378987256898, 'reg_lambda': 0.6018695418190363, 'reg_alpha': 1.0087186320200285}. Best is trial 162 with value: 0.8420744148953054.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:49:24,124]\u001b[0m Trial 207 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:49:27,728]\u001b[0m Trial 208 finished with value: 0.754863083832297 and parameters: {'learning_rate': 0.8762144469093618, 'min_split_loss': 0.8848980898595952, 'max_depth': 42, 'min_child_weight': 6.255342542167431, 'reg_lambda': 0.27295813323819873, 'reg_alpha': 0.8998526752208185}. Best is trial 162 with value: 0.8420744148953054.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:49:30,717]\u001b[0m Trial 209 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:49:33,115]\u001b[0m Trial 210 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2021-08-20 10:49:36,250]\u001b[0m Trial 211 pruned. Trial was pruned at iteration 3.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study.optimize(objective, n_trials=256, callbacks=[keep_best_bandgap_model])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# ROC Curves\n",
    "\n",
    "To assess model performance, we'll print out some ROC curves here.\n",
    "\n",
    "Although we hold out a validation set in our objective function, we do not retrain the model on the entire training set, as this validation set was also used to control the early stopping of our XGBoost model (and thus helps guard against overfitting).\n",
    "\n",
    "Overall, we see generally good results for both our training set and our testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "labels = {j[0]:i for (i,j) in cutoffs.items()}\n",
    "\n",
    "def plot_multi_roc(x, y, dataset_label, custom_labels=None, classifier=best_pipeline):\n",
    "        plt.rcParams['figure.figsize'] = [10,10]\n",
    "\n",
    "        classes = set(y)\n",
    "        fig, ax = plt.subplots()\n",
    "\n",
    "        for class_label in classes:\n",
    "            probabilities = classifier.predict_proba(x)[:,class_label]\n",
    "\n",
    "            # ROC curve function in sklearn prefers the positive class\n",
    "            false_positive_rate, true_positive_rate, thresholds = sklearn.metrics.roc_curve(y, probabilities,\n",
    "                                                                                            pos_label=class_label)\n",
    "            roc_auc = np.round(sklearn.metrics.auc(false_positive_rate, true_positive_rate), 3)\n",
    "            \n",
    "            if custom_labels is None:\n",
    "                label = f\"Class {class_label}\"\n",
    "            else:\n",
    "                label = custom_labels[class_label]\n",
    "            ax.plot(false_positive_rate, true_positive_rate, label=f\"{label}, AUC ROC={roc_auc}\")\n",
    "\n",
    "        # Padding to ensure we see the line\n",
    "        ax.margins(0.01)\n",
    "        ax.legend()\n",
    "        fig.patch.set_facecolor('white')\n",
    "        plt.plot([0,1], [0,1], c='k')\n",
    "        plt.title(f\"{dataset_label} Set ROC curves\")\n",
    "        plt.xlabel(\"False Positive Rate\")\n",
    "        plt.ylabel(\"True Positive Rate\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{dataset_label}_Set_ROC.png\")\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        \n",
    "plot_multi_roc(train_x, train_y, \"Training\", labels)\n",
    "plot_multi_roc(test_x, test_y, \"Test\", labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Confusion Matrices\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def draw_confusion_matrix(x, y, label, classnames, classifier):\n",
    "    plt.rcParams['figure.facecolor'] = 'white'\n",
    "    sklearn.metrics.ConfusionMatrixDisplay(\n",
    "        sklearn.metrics.confusion_matrix(\n",
    "            y_true=y,\n",
    "            y_pred=classifier.predict(x),\n",
    "        )\n",
    "    ).plot(cmap=\"Blues\")\n",
    "    plt.title(f\"{label} Set Confusion Matrix\")\n",
    "    plt.xticks(range(len(classnames)), labels=classnames)\n",
    "    plt.yticks(range(len(classnames)), labels=classnames)\n",
    "    plt.gca().xaxis.tick_top()\n",
    "    plt.savefig(f\"{label}_set_confusion_matrix.png\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "classnames = [key for key in cutoffs.keys()]\n",
    "draw_confusion_matrix(train_x, train_y, \"Training\", classnames, best_pipeline)\n",
    "draw_confusion_matrix(test_x, test_y, \"Test\", classnames, best_pipeline)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (sisso_collab)",
   "language": "python",
   "name": "pycharm-ac18fefc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
